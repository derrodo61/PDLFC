{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PDLFC01 - is it a bird?","metadata":{}},{"cell_type":"markdown","source":"*Note: this is a kaggle notebook. Using it on Google Colab would require the installation of additional packages.*\n\nSample code from the course \"Practical Deep Learning for Coders\".\n\nContent:\n\n- Performing a duckduckgo search for images of birds and forrest\n- Downlaod the results\n- Train the model\n- Use the model","metadata":{}},{"cell_type":"markdown","source":"## Basic installations","metadata":{}},{"cell_type":"code","source":"#NB: Kaggle requires phone verification to use the internet or a GPU. If you haven't done that yet, the cell below will fail\n#    This code is only here to check that your internet is enabled. It doesn't do anything else.\n#    Here's a help thread on getting your phone number verified: https://www.kaggle.com/product-feedback/135367\n\nimport socket,warnings\ntry:\n    socket.setdefaulttimeout(1)\n    socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(('1.1.1.1', 53))\nexcept socket.error as ex: raise Exception(\"STOP: No internet. Click '>|' in top right and set 'Internet' switch to on\")","metadata":{"execution":{"iopub.status.busy":"2024-07-13T10:39:40.976020Z","iopub.execute_input":"2024-07-13T10:39:40.976415Z","iopub.status.idle":"2024-07-13T10:39:41.014904Z","shell.execute_reply.started":"2024-07-13T10:39:40.976315Z","shell.execute_reply":"2024-07-13T10:39:41.014247Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"This messages from pip can be ignored:\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.","metadata":{}},{"cell_type":"code","source":"# It's a good idea to ensure you're running the latest version of any libraries you need.\n# `!pip install -Uqq <libraries>` upgrades to the latest version of <libraries>\n# NB: You can safely ignore any warnings or errors pip spits out about running as root or incompatibilities\nimport os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\nif iskaggle:\n    !pip install -Uqq fastai duckduckgo_search","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-13T10:40:55.935145Z","iopub.execute_input":"2024-07-13T10:40:55.935977Z","iopub.status.idle":"2024-07-13T10:41:05.680243Z","shell.execute_reply.started":"2024-07-13T10:40:55.935940Z","shell.execute_reply":"2024-07-13T10:41:05.679154Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"But today, we can do exactly that, in just a few minutes, using entirely free resources!\n\nThe basic steps we'll take are:\n\n1. Use DuckDuckGo to search for images of \"bird photos\"\n1. Use DuckDuckGo to search for images of \"forest photos\"\n1. Fine-tune a pretrained neural network to recognise these two groups\n1. Try running this model on a picture of a bird and see if it works.","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Download images of birds and non-birds","metadata":{}},{"cell_type":"code","source":"# rd: fixed version: 07.07.2024\n# fix: https://github.com/andersglindstrom/download_ddg_birds/blob/main/download-ddg.ipynb\n\n!pip install -Uqq duckduckgo-images-api\n!pip install -Uqq fastbook\n\nfrom fastbook import search_images_ddg\nfrom fastcore.all import *\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return search_images_ddg(term, max_images=max_images)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T10:42:09.248943Z","iopub.execute_input":"2024-07-13T10:42:09.249214Z","iopub.status.idle":"2024-07-13T10:42:31.404627Z","shell.execute_reply.started":"2024-07-13T10:42:09.249186Z","shell.execute_reply":"2024-07-13T10:42:31.403941Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"- Search for forest and bird.\n- Serach in 3 variations (photo, sun photo, shade photo)\n- Default: 30 results\n- Download the images\n- Resize all downloaded images \n","metadata":{}},{"cell_type":"code","source":"searches = 'forest','bird'\npath = Path('bird_or_not')\nfrom time import sleep\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} sun photo'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} shade photo'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T10:44:06.902682Z","iopub.execute_input":"2024-07-13T10:44:06.902967Z","iopub.status.idle":"2024-07-13T10:45:39.014880Z","shell.execute_reply.started":"2024-07-13T10:44:06.902938Z","shell.execute_reply":"2024-07-13T10:45:39.013968Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Searching for 'forest photo'\nSearching for 'forest sun photo'\nSearching for 'forest shade photo'\nSearching for 'bird photo'\nSearching for 'bird sun photo'\nSearching for 'bird shade photo'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 2: Train the model","metadata":{}},{"cell_type":"markdown","source":"Remove photos which might not be download correctly.","metadata":{}},{"cell_type":"code","source":"failed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T10:48:02.516692Z","iopub.execute_input":"2024-07-13T10:48:02.517511Z","iopub.status.idle":"2024-07-13T10:48:02.905867Z","shell.execute_reply.started":"2024-07-13T10:48:02.517469Z","shell.execute_reply":"2024-07-13T10:48:02.905068Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"markdown","source":"To train a model, we'll need `DataLoaders`, which is an object that contains a *training set* (the images used to create a model) and a *validation set* (the images used to check the accuracy of a model -- not used during training). In `fastai` we can create that easily using a `DataBlock`, and view sample images from it:","metadata":{}},{"cell_type":"code","source":"dls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path, bs=32)\n\ndls.show_batch(max_n=6)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T07:40:50.823532Z","iopub.execute_input":"2024-07-13T07:40:50.824252Z","iopub.status.idle":"2024-07-13T07:40:54.659680Z","shell.execute_reply.started":"2024-07-13T07:40:50.824215Z","shell.execute_reply":"2024-07-13T07:40:54.658920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here what each of the `DataBlock` parameters means:\n\n    blocks=(ImageBlock, CategoryBlock),\n\nThe inputs to our model are images, and the outputs are categories (in this case, \"bird\" or \"forest\").\n\n    get_items=get_image_files, \n\nTo find all the inputs to our model, run the `get_image_files` function (which returns a list of all image files in a path).\n\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n\nSplit the data into training and validation sets randomly, using 20% of the data for the validation set.\n\n    get_y=parent_label,\n\nThe labels (`y` values) is the name of the `parent` of each file (i.e. the name of the folder they're in, which will be *bird* or *forest*).\n\n    item_tfms=[Resize(192, method='squish')]\n\nBefore training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it).","metadata":{}},{"cell_type":"markdown","source":"Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n\n`fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that.","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)","metadata":{"execution":{"iopub.status.busy":"2024-07-13T07:41:08.717275Z","iopub.execute_input":"2024-07-13T07:41:08.717607Z","iopub.status.idle":"2024-07-13T07:41:20.902917Z","shell.execute_reply.started":"2024-07-13T07:41:08.717570Z","shell.execute_reply":"2024-07-13T07:41:20.902042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generally when I run this I see 100% accuracy on the validation set (although it might vary a bit from run to run).\n\n\"Fine-tuning\" a model means that we're starting with a model someone else has trained using some other dataset (called the *pretrained model*), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in *imagenet*, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it's important, check out the [free fast.ai course](https://course.fast.ai/).","metadata":{}},{"cell_type":"markdown","source":"## Step 3: Use our model (and build your own!)","metadata":{}},{"cell_type":"markdown","source":"Let's see what our model thinks about that bird we downloaded at the start:","metadata":{}},{"cell_type":"code","source":"is_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-13T07:41:26.706069Z","iopub.execute_input":"2024-07-13T07:41:26.706355Z","iopub.status.idle":"2024-07-13T07:41:26.942201Z","shell.execute_reply.started":"2024-07-13T07:41:26.706325Z","shell.execute_reply":"2024-07-13T07:41:26.941438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Good job, resnet18. :)\n\nSo, as you see, in the space of a few years, creating computer vision classification models has gone from \"so hard it's a joke\" to \"trivially easy and free\"!\n\nIt's not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including [creating amazing artworks](https://openai.com/dall-e-2/), and [explaining jokes](https://www.datanami.com/2022/04/22/googles-massive-new-language-model-can-explain-jokes/). It's moving so fast that even experts in the field have trouble predicting how it's going to impact society in the coming years.\n\nOne thing is clear -- it's important that we all do our best to understand this technology, because otherwise we'll get left behind!","metadata":{}},{"cell_type":"markdown","source":"Now it's your turn. Click \"Copy & Edit\" and try creating your own image classifier using your own image searches!\n\nIf you enjoyed this, please consider clicking the \"upvote\" button in the top-right -- it's very encouraging to us notebook authors to know when people appreciate our work.","metadata":{}}]}